;; gorilla-repl.fileformat = 1

;; **
;;; # New Scheduler Perf:
;;; 
;;; 2 examples per out-group
;;; 
;;; Full model retrieval performance:
;;; 
;;;     http://grails.1312388.n4.nabble.com/ - 0.96 - 100
;;;     http://r.789695.n4.nabble.com/ - 0.96 - 150
;;;     http://osgeo-org.1560.x6.nabble.com/ - 0.88 - 200
;;;     http://imagej.1557.x6.nabble.com/ - 0.96 - 200
;;;     http://t58.1557.x6.nabble.com/ - 0.89 - 200
;;;     http://ruralmail.com/ - 0.87 - 200
;;; 
;;; 
;;; 
;; **

;; **
;;; # Detect Forum Leaf Node
;;; 
;;; This is a set of experiments on building a forum leaf detection module.
;; **

;; **
;;; Features:
;;; 1. jaccard similarity between anchor text and page-text
;;; 2. size of anchor-text language model
;;; 
;;;     Decision tree results:
;;;     Correctly Classified Instances          68               83.9506 %
;;;     Incorrectly Classified Instances        13               16.0494 %
;;;     Kappa statistic                          0.5979
;;;     Mean absolute error                      0.2647
;;;     Root mean squared error                  0.3638
;;;     Relative absolute error                 59.3884 %
;;;     Root relative squared error             77.1771 %
;;;     Total Number of Instances               81     
;;; 
;;; 
;;; So clearly this metric is not v good. Next idea I would like to try is:
;;; 
;;; * cosine similarity
;;; * remove links off the page and then attempt to perform this classification?
;;; * relationship between links and page content
;;; * date (o god fucking no)
;;; * anchor windows idea?
;;; 
;;; 
;;; Adding more features to this sucker:
;;; 
;;; With stop word count as classifier
;;; 
;;; Train Error:
;;;     === Confusion Matrix ===
;;; 
;;;     a  b   <-- classified as
;;;     45  4 |  a = 1
;;;     4 50 |  b = 0
;;; 
;;;     === Summary ===
;;; 
;;;     Correctly Classified Instances          95               92.233  %
;;;     Incorrectly Classified Instances         8                7.767  %
;;;     Kappa statistic                          0.8443
;;;     Mean absolute error                      0.1369
;;;     Root mean squared error                  0.2617
;;;     Relative absolute error                 27.4502 %
;;;     Root relative squared error             52.3941 %
;;;     Total Number of Instances              103
;;;     
;;; 
;;; Test Error:
;;;     === Confusion Matrix ===
;;; 
;;;     a  b   <-- classified as
;;;     18  1 |  a = 1
;;;     6 16 |  b = 0
;;; 
;;;     === Summary ===
;;; 
;;;     Correctly Classified Instances          34               82.9268 %
;;;     Incorrectly Classified Instances         7               17.0732 %
;;;     Kappa statistic                          0.6627
;;;     Mean absolute error                      0.2189
;;;     Root mean squared error                  0.3845
;;;     Relative absolute error                 44.0037 %
;;;     Root relative squared error             77.1051 %
;;;     Total Number of Instances               41
;;;     
;;;     
;;; anchor text stop-words resulted a drop in perf. How about using how many stop words come from anchors vs the body (user-generated content links vs text i.e.)
;;; 
;;; the ratio also performs poorly:
;;; 
;;; 
;;; Train Error:
;;;     === Confusion Matrix ===
;;; 
;;;     a  b   <-- classified as
;;;     45  4 |  a = 1
;;;     3 51 |  b = 0
;;; 
;;;     === Summary ===
;;; 
;;;     Correctly Classified Instances          96               93.2039 %
;;;     Incorrectly Classified Instances         7                6.7961 %
;;;     Kappa statistic                          0.8636
;;;     Mean absolute error                      0.124 
;;;     Root mean squared error                  0.249 
;;;     Relative absolute error                 24.8506 %
;;;     Root relative squared error             49.8515 %
;;;     Total Number of Instances              103     
;;; 
;;; Test Error:
;;;     === Confusion Matrix ===
;;; 
;;;     a  b   <-- classified as
;;;     17  2 |  a = 1
;;;     6 16 |  b = 0
;;; 
;;;     === Summary ===
;;; 
;;;     Correctly Classified Instances          33               80.4878 %
;;;     Incorrectly Classified Instances         8               19.5122 %
;;;     Kappa statistic                          0.6132
;;;     Mean absolute error                      0.2357
;;;     Root mean squared error                  0.4222
;;;     Relative absolute error                 47.376  %
;;;     Root relative squared error             84.6694 %
;;;     Total Number of Instances               41  
;;;     
;;; Since this feature has also bombed what next?
;;; 
;;; 
;;; Also a couple more ideas, let us go try this exact feature set with an SVM
;;; 
;;; First we need to confirm what kind of error this is. If the guy is producing some errors that we don't like (for instance poor precision on just discussion pages but high accuracy on others)
;;; 
;;; Ok, massive accuracy improvement moving to SVM.
;;; 
;;; Feature Set:
;;; 
;;; 1. Jaccard Similarity between anchor-text language-model and body language-model
;;; 2. number of unique tokens in the outlink-text of the webpage
;;; 3. Retrieve all links on page - the average gap between the links on the webpage
;;; 4. Number of stopwords in links on the page
;;; 5. number of stopwords in the body
;;; 6. Number of single-token links
;;; 
;;; On our test set:
;;; 
;;;     {:fail 6, :success 56}
;;; 
;;; Training set construction:
;;; 
;;; 1. Set of 103 training documents:
;;;    3 vBulletin forums
;;;    3 ipBoard forums
;;;    3 phpbb forums
;;;    
;;;    from each of these forums, we have 3 index pages + 3 author pages (i.e. NOT discussion) and 6 discussion pages.
;;;    
;;; 2. Set of 62 test documents:
;;;    Same as above, combine vb, phpbb, ipboard and SMF. author, index and discussion pages combined.
;;;    
;;; Misclassification analysis:
;;; 
;;; out of 62 documents: 4 discussion pages identified as otherwise (acceptable), 2 non-discussion pages identified as otherwise - one of these was an author page: vocabulary strategy for disambiguating
;;;    
;;; 
;;; 
;;; 
;; **

;; @@

;; @@
